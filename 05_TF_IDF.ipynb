{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "05 - TF-IDF.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrybrew/text-mining/blob/master/05_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WaarhlzwwyY",
        "colab_type": "text"
      },
      "source": [
        "# Lab 05 - TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lbNkEbXwwyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Release: 1.1909.0901"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fbMjK5ZuSzo",
        "colab_type": "text"
      },
      "source": [
        "You will learn how to:\n",
        "1. Calculate TF-IDF using TfidfVectorizer\n",
        "2. View data in pandas DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDxxOLWSxXKt",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        " \n",
        "***If you use Google Colab, install sastrawi package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXlqC5VMGVIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvpt5WAjwwzX",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Import required library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcIf7Iycwwzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzbzSn9hGXY-",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        " \n",
        "***If you use Google Colab, download stopwords dan punkt package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm7aIacRGYLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCIA9ttNwwz5",
        "colab_type": "text"
      },
      "source": [
        "#### Prepocessing function from previous labs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lnUM10vww0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_clean(text):\n",
        "    \n",
        "    #tokenisasi\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
        "        in nltk.word_tokenize(sent)]\n",
        "    \n",
        "    #clean token from numeric and other character like puntuation\n",
        "    filtered_tokens = []\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un3kww8dww0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('indonesian')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM0wpjDdww1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(tokenized_text):\n",
        "    \n",
        "    cleaned_token = []\n",
        "    for token in tokenized_text:\n",
        "        if token not in stopwords:\n",
        "            cleaned_token.append(token)\n",
        "            \n",
        "    return cleaned_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFfBuE8Dww1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming_text(tokenized_text):\n",
        "    \n",
        "    #stem using Sastrawi StemmerFactory \n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "\n",
        "    stems = []\n",
        "    for token in tokenized_text:\n",
        "        stems.append(stemmer.stem(token))\n",
        "\n",
        "    return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXu8-Aj-ww1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \n",
        "    prep01 = tokenize_clean(text)\n",
        "    prep02 = remove_stopwords(prep01)\n",
        "    prep03 = stemming_text(prep02)\n",
        "    \n",
        "    return prep03\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHeRibYJww2X",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 01 - Create dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJG5-KFw5-i_",
        "colab_type": "text"
      },
      "source": [
        "Create simple dataset contain 5 sentences (docs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yOP2AE_ww2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = []\n",
        "files.append(\"Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam ditangan.\")\n",
        "files.append(\"Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.\")\n",
        "files.append(\"Lombok memang memiliki sejuta pesona yang mampu menyedot perhatian orang untuk datang berwisata.\")\n",
        "files.append(\"Perempuan yang bergelut di dunia kerelawanan akan belajar caranya bertanggung jawab bagi sendiri dan orang lain.\")\n",
        "files.append(\"Kami berkoordinasi dan melapor pada posko relawan, kami berkomitmen  siap membantu dengan siaga 24 jam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tECPhuiBww22",
        "colab_type": "text"
      },
      "source": [
        "### Step 02 - Corpus preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTF3-1Zoww28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare corpus, load it into dictionary\n",
        "token_dict = {}\n",
        "i = 0\n",
        "for t in files:\n",
        "    filename = \"file\" + str(i)\n",
        "    token_dict[filename] = t\n",
        "    i = i + 1\n",
        "\n",
        "token_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NKDlta6ww3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict.values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y807GgxBmr19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict['file0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaqdY5ub0qBI",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "Tfidfvectorizer will compute the word counts, idf and tfidf values all at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtk7bCewww3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform tf-idf vectorization\n",
        "tfidf = TfidfVectorizer(max_df=0.8,             # terms with document frequency value > 0.8 will be removed\n",
        "                        min_df=0.2,             # terms with document frequency value < 0.2 will be removed\n",
        "                        max_features=200000,    # create maximum 200.000 vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "                        stop_words = stopwords, # stopwords list\n",
        "                        use_idf=True,           # enable inverse-document-frequency reweighting\n",
        "                        tokenizer=text_preprocessing, # override the string tokenization step by using text_prepocessing function \n",
        "                        ngram_range=(1,3))      # ngram range 1 - 3 \n",
        "\n",
        "\n",
        "tfs = tfidf.fit_transform(token_dict.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UiKq2zstfCm",
        "colab_type": "text"
      },
      "source": [
        "For detail TfidfVectorizer documentation visit: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiP7oyemzmFp",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "Let's check the shape. We should have 5 rows (5 docs) and 96 columns (96 unique words):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SldlNnVHww3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bp_BXCf4jll",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "Inspect the first document vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ_-jpQnww3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tfs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiZGc0tBr8wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_names = tfidf.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hwA_HIGsCyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(feature_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCvGLeCHsGq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nt8qLn0qZYr",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "print IDF value by using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYMpQL-Hww4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# print idf values\n",
        "df_idf = pd.DataFrame(tfidf.idf_, index=feature_names,columns=[\"idf\"])\n",
        " \n",
        "# sort ascending\n",
        "df_idf.sort_values(by=['idf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUcxIdanww4b",
        "colab_type": "text"
      },
      "source": [
        "### Step 03 - TF-IDF Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA4eghYaww4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str1 = 'Di kejauhan tampak seorang relawan pria dari Lombok sedang berjalan.'\n",
        "response = tfidf.transform([str1])\n",
        "\n",
        "#show result\n",
        "for col in response.nonzero()[1]:\n",
        "    print (feature_names[col], ' - ', response[0, col])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39V3PGdWrALP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGayyzqEww43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (text_preprocessing(str1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGwbAFiZww5t",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "### Using Smaller Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnb7UrJHww5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of text documents\n",
        "text = [\"Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.\",\n",
        "        \"Masyarakat tak mau erupsi\",\n",
        "        \"Rupanya waktu erupsi\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTYZbu9eslXs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph9eKGMVww6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the transform\n",
        "vectorizer = TfidfVectorizer(tokenizer=text_preprocessing)\n",
        "\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpFCJoLLww6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.idf_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOcEbfi9ww6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print idf values\n",
        "df_idf = pd.DataFrame(vectorizer.idf_, index=vectorizer.get_feature_names(),columns=[\"idf\"])\n",
        " \n",
        "# sort ascending\n",
        "df_idf.sort_values(by=['idf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgseqJtXww6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode document\n",
        "vector = vectorizer.transform([text[0]])\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7UmbF3oww61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdf6YGIfub1k",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "#### Revision History:\n",
        "Release: 1.1907.1601\n",
        "- Initial release\n",
        "\n",
        "Release: 1.1909.0901\n",
        "- Install sastrawi package to support Google Colab\n",
        "- Reorganize code"
      ]
    }
  ]
}