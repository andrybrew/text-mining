{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "06 - Text Clustering - Putting It All Together.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrybrew/text-mining/blob/master/06_Text_Clustering_Putting_It_All_Together.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am-_A8L24id7",
        "colab_type": "text"
      },
      "source": [
        "# Lab 06 - DOCUMENT CLUSTERING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK8rnr1q4ieW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Release: 1.1909.0901"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqN-SnP8Z-Zw",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        " \n",
        "***If you use Google Colab, install sastrawi package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZLJn6Ry7IBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXFx2tZK4ifN",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Import required library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejV7KDD4ifY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import re \n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "#from sklearn.externals import joblib\n",
        "from sklearn.manifold import MDS\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnMijOCkZEsA",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        " \n",
        "***If you use Google Colab, download stopwords dan punkt package***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfbPHY8f5CXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjpI9QIGtKlq",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### Download dataset from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu34spnjtRH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/project303/dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WFyI9lL7ymG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqVDukxJ4if3",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 01 - Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gxOXZNS4igD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load titles\n",
        "titles = open('dataset/Judul Berita.txt').read().split('\\n')\n",
        "len(titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeGmF-y_4igb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titles[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOn87GXN4ig3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPclpSke4ihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article = open('dataset/Berita.txt', encoding=\"utf8\").read().split('BERHENTI DISINI')\n",
        "len(article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yA3yeL34ihm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article = article[:31]\n",
        "print(article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zCFipv24iiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article_clean = []\n",
        "for text in article:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    article_clean.append(text)\n",
        "article = article_clean\n",
        "print(article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auk2uSbw4iia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(str(len(titles)) + ' titles')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6gJBv064iiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(str(len(article)) + ' article')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpdVdEgj4ijJ",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 02 - Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsdtYTWU4ijO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_only(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R-8vjGk4ijl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totalvocab_tokenized = []\n",
        "for i in article:\n",
        "    allwords_tokenized = tokenize_only(i)\n",
        "    totalvocab_tokenized.extend(allwords_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLRqVzbB4ij1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(totalvocab_tokenized))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGS6T4wh4ikJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(totalvocab_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FrhHSZE4ika",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 03 - Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhrEGzFR4ikf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMwBM7544ilC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_stem(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-QrPFF4ilR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totalvocab_stemmed = []\n",
        "for i in article:\n",
        "    \n",
        "    allwords_stemmed = tokenize_and_stem(i) # for each item in 'article', tokenize/stem\n",
        "    totalvocab_stemmed.extend(allwords_stemmed) # extend the 'totalvocab_stemmed' list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKPybiJU4ilj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(totalvocab_stemmed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jweLmTmp4il0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(totalvocab_stemmed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWDElMiz4imC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
        "print('ada ' + str(vocab_frame.shape[0]) + ' kata di vocab_frame')\n",
        "print(vocab_frame.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGeNwTPP4imU",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 04 - TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4T2NTnc4imX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ranks = []\n",
        "for i in range(1, len(titles)+1):\n",
        "    ranks.append(i)\n",
        "\n",
        "ranks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na9ScKjg9Q6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLa9fmSy4imm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('indonesian')\n",
        "\n",
        "print('number of stopwords: ' + str(len(stopwords)))\n",
        "#stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXeoAwet4im5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
        "                                 min_df=0.2, stop_words = stopwords,\n",
        "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckykQ9854inE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().magic(u'time tfidf_matrix = tfidf_vectorizer.fit_transform(article) #fit the vectorizer to article')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EvaIW_B4inQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tfidf_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbQwmWPr4inh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tfidf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn_8Dy6Y4inq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = tfidf_vectorizer.get_feature_names()\n",
        "len(terms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV6POr3u4in8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity = cosine_similarity(tfidf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX5UBosp4ioJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZqZ7cVK4ioT",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 05 - K-Means Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZqngwsH4ioY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_clusters = 3\n",
        "km = KMeans(n_clusters=num_clusters, random_state=1000)\n",
        "get_ipython().magic(u'time km.fit(tfidf_matrix)')\n",
        "clusters = km.labels_.tolist()\n",
        "#clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nJ4nlD4ioj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news = { 'title': titles, 'rank': ranks, 'article': article, 'cluster': clusters }\n",
        "frame = pd.DataFrame(news, index = [clusters] , columns = ['rank', 'title', 'cluster'])\n",
        "print(frame) \n",
        "frame['cluster'].value_counts() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmwSlCIX4iot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = frame['rank'].groupby(frame['cluster']) \n",
        "grouped.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OECnFT0d4io5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Top terms per cluster:\")\n",
        "#sort cluster centers by proximity to centroid\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
        "\n",
        "for i in range(num_clusters):\n",
        "    print(\"Cluster %d words:\" % i, end='')\n",
        "    \n",
        "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
        "        print(' %s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
        "    print() #add whitespace\n",
        "    print() #add whitespace\n",
        "    \n",
        "    print(\"Cluster %d titles:\" % i, end='')\n",
        "    for title in frame.loc[i]['title'].values.tolist():\n",
        "        print(' %s,' % title, end='')\n",
        "    print() #add whitespace\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvoke3mc4ipE",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### Step 06 - Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BJdhfry4ipH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similarity_distance = 1 - cosine_similarity(tfidf_matrix)\n",
        "print(type(similarity_distance))\n",
        "print(similarity_distance.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cN0J7bv4ipQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
        "get_ipython().magic(u'time pos = mds.fit_transform(similarity_distance)  # shape (n_components, n_samples)')\n",
        "print(pos.shape)\n",
        "print(pos)\n",
        "xs, ys = pos[:, 0], pos[:, 1]\n",
        "print(type(xs))\n",
        "xs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXtIwsJJ4ipZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up colors per clusters using a dict\n",
        "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJZjEib4ipl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up cluster names using a dict\n",
        "cluster_names = {0: 'Olahraga', \n",
        "                 1: 'Ekonomi', \n",
        "                 2: 'Kriminal'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLbbVwCk4ipu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB77ozHY4ip6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#some ipython magic to show the matplotlib plots inline\n",
        "get_ipython().magic(u'matplotlib inline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTVfx-_q4iqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
        "\n",
        "print(df[1:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDYD4rP44iqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# group by cluster\n",
        "# this generate {name:group(which is a dataframe)}\n",
        "groups = df.groupby('label')\n",
        "print(groups.groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uk8BI2J4iqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up plot\n",
        "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
        "# ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "#iterate through groups to layer the plot\n",
        "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "# ms: marker size\n",
        "for name, group in groups:\n",
        "    #print(\"*******\")\n",
        "    #print(\"group name \" + str(name))\n",
        "    #print(group)\n",
        "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=20, \n",
        "            label=cluster_names[name], color=cluster_colors[name], \n",
        "            mec='none')\n",
        "    ax.set_aspect('auto')\n",
        "    ax.tick_params(        axis= 'x',          # changes apply to the x-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        bottom='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelbottom='off')\n",
        "    ax.tick_params(        axis= 'y',         # changes apply to the y-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        left='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelleft='off')\n",
        "    \n",
        "ax.legend(numpoints=1)  #show legend with only 1 point\n",
        "\n",
        "#add label in x,y position with the label as the film title\n",
        "for i in range(len(df)):\n",
        "    ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['title'], size=10)  \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efm7P64p4iqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGS4xMJR4iq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}