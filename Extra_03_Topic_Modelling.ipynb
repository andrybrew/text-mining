{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Extra 03 - Topic Modelling.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrybrew/text-mining/blob/master/Extra_03_Topic_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6RsxfhLMmNj",
        "colab_type": "text"
      },
      "source": [
        "## Using Gensim for Topic Modeling\n",
        "\n",
        "We’re going to use the gensim implementations because they offer more functionality out of the box and then we’ll replicate that functionality with sklearn. Let’s first prepare the dataset we’ll be working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgsW77oiMmOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sastrawi\n",
        "!pip install pyldavis\n",
        "!pip install gensim==3.8.0\n",
        "\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import re \n",
        "\n",
        "import re\n",
        "from gensim import models, corpora\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbC7w3gAz9GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim==3.8.0\n",
        "import pkg_resources\n",
        "pkg_resources.get_distribution(\"gensim\").version\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv6ylsJkMmO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/project303/dataset.git\n",
        "  \n",
        "article = open('dataset/Berita.txt', encoding=\"utf8\").read().split('BERHENTI DISINI')\n",
        "len(article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgTfNBEMMmPT",
        "colab_type": "text"
      },
      "source": [
        "Clean the data from html tags with ``beautifulsoup``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXEw_pGrMmPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article_clean = []\n",
        "for text in article:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    article_clean.append(text)\n",
        "article = article_clean\n",
        "print(article[0][:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_V1VWiNMmP6",
        "colab_type": "text"
      },
      "source": [
        "Tokenize and clean stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVe7-J0dMmQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5g0Y_RcMmQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_stem(text):\n",
        "    stopwords = nltk.corpus.stopwords.words('indonesian')\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token) and token not in stopwords:\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKTUOCW2MmQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For gensim we need to tokenize the data and filter out stopwords\n",
        "tokenized_data = []\n",
        "for text in article:\n",
        "    tokenized_data.append(tokenize_and_stem(text))\n",
        "\n",
        "# Build a Dictionary - association word to numeric id\n",
        "dictionary = corpora.Dictionary(tokenized_data)\n",
        " \n",
        "# Transform the collection of texts to a numerical form\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n",
        " \n",
        "# Have a look at how the 20th document looks like: [(word_id, count), ...]\n",
        "print(corpus[20])\n",
        "# [(12, 3), (14, 1), (21, 1), (25, 5), (30, 2), (31, 5), (33, 1), (42, 1), (43, 2),  ...\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWPxNZZIMmRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_TOPICS = 4\n",
        "\n",
        "# Build the LDA model\n",
        "lda_model = models.LdaModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary, alpha = 'auto', eval_every=5)#, per_word_topics=True)\n",
        " \n",
        "# Build the LSI model\n",
        "lsi_model = models.LsiModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R40g_yruMmRc",
        "colab_type": "text"
      },
      "source": [
        "We’re going to run LDA and LSI (Latent Semantic Indexing AKA Latent Semantic Analysis) models, which implementation included in the gensim package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV9w7E78MmRk",
        "colab_type": "text"
      },
      "source": [
        "Let’s now display the topics the two models have inferred:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mELANWUoMmRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"LDA Model:\")\n",
        " \n",
        "for idx in range(NUM_TOPICS):\n",
        "    # Print the first 10 most representative topics\n",
        "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 10))\n",
        " \n",
        "print(\"=\" * 20)\n",
        " \n",
        "print(\"LSI Model:\")\n",
        " \n",
        "for idx in range(NUM_TOPICS):\n",
        "    # Print the first 10 most representative topics\n",
        "    print(\"Topic #%s:\" % idx, lsi_model.print_topic(idx, 10))\n",
        " \n",
        "print(\"=\" * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_ZwrWDcMmR4",
        "colab_type": "text"
      },
      "source": [
        "Let’s now put the models to work and transform unseen documents to their topic distribution:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8UavFS_MmR9",
        "colab_type": "raw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-zr827vMmSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"Pertandingan berjalan dengan seru. Tim lawan berhasil dikalahkan dengan skor 1-0.\"\n",
        "bow = dictionary.doc2bow(tokenize_and_stem(text))\n",
        "\n",
        "print(lda_model[bow]) \n",
        "print(lsi_model[bow])\n",
        "print(bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwyfJw16MmST",
        "colab_type": "text"
      },
      "source": [
        "The LDA result can be interpreted as a distribution over topics.\n",
        "Gensim offers a simple way of performing similarity queries using topic models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5I1jtKIMmSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import similarities\n",
        " \n",
        "lda_index = similarities.MatrixSimilarity(lda_model[corpus])\n",
        " \n",
        "# Let's perform some queries\n",
        "similarities = lda_index[lda_model[bow]]\n",
        "# Sort the similarities\n",
        "similarities = sorted(enumerate(similarities), key=lambda item: -item[1])\n",
        " \n",
        "# Top most similar documents:\n",
        "print(similarities[:10])\n",
        " \n",
        "# Let's see what's the most similar document\n",
        "document_id, similarity = similarities[0]\n",
        "print(article[document_id][:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCZF_sNeMmSm",
        "colab_type": "text"
      },
      "source": [
        "Notice how the factors corresponding to each component (topic) add up to 1. That’s not a coincidence. Indeed, LDA considers documents as being generated by a mixture of the topics. The purpose of LDA is to compute how much of the document was generated by which topic. \n",
        "\n",
        "LDA is an iterative algorithm. Here are the two main steps:\n",
        "\n",
        "   - In the initialization stage, each word is assigned to a random topic.\n",
        "   - Iteratively, the algorithm goes through each word and reassigns the word to a topic taking into consideration:\n",
        "        - What’s the probability of the word belonging to a topic\n",
        "        - What’s the probability of the document to be generated by a topic\n",
        "\n",
        "Due to these important qualities, we can visualize LDA results easily. We’re going to use a specialized tool called PyLDAVis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bb1OMVOMmSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyLDAvis.gensim\n",
        " \n",
        "pyLDAvis.enable_notebook()\n",
        "panel = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "panel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am6BihdBMmS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwdKhq8bMmTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tRkt-YTMmTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwGpyS8jMmTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}